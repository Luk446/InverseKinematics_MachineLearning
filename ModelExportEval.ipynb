{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages - python kernel must be version 3.12 or below !\n",
    "# a lot of these packages are not needed for this notebook, but are taken from the original notebook\n",
    "\n",
    "# ML packages\n",
    "\n",
    "# torch\n",
    "import torch # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "import torch.nn.functional as F # type: ignore\n",
    "from torch import nn # type: ignore\n",
    "from torch.utils.data import Dataset, DataLoader # type: ignore\n",
    "from torch.utils.data import random_split  # type: ignore\n",
    "from torchvision.transforms import ToTensor # type: ignore\n",
    "from torch.utils.data import TensorDataset, DataLoader # type: ignore\n",
    "import torchvision # type: ignore\n",
    "import torchvision.transforms as transforms # type: ignore\n",
    "from torchmetrics.regression import MeanAbsolutePercentageError  # type: ignore\n",
    "from torchmetrics.regression import MeanSquaredError  # type: ignore\n",
    "from torchmetrics.regression import MeanAbsoluteError  # type: ignore\n",
    "from torchinfo import summary #type:ignore\n",
    "\n",
    "# tuning\n",
    "import ray # type: ignore\n",
    "from ray import tune  # type: ignore\n",
    "from ray import train  # type: ignore\n",
    "from ray.tune import CLIReporter  # type: ignore\n",
    "from ray.tune.schedulers import ASHAScheduler  # type: ignore\n",
    "from ray.train import Checkpoint, get_checkpoint  # type: ignore\n",
    "from ray.tune.schedulers import ASHAScheduler  # type: ignore\n",
    "import ray.cloudpickle as pickle  # type: ignore\n",
    "\n",
    "\n",
    "# linear algebra, array manip and data analysis\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "from mpl_toolkits.mplot3d import Axes3D # type: ignore\n",
    "from sklearn.model_selection import train_test_split # type: ignore\n",
    "from sklearn.preprocessing import StandardScaler # type: ignore\n",
    "from tabulate import tabulate # type: ignore\n",
    "\n",
    "# misc\n",
    "from functools import partial\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>roll</th>\n",
       "      <th>pitch</th>\n",
       "      <th>yaw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1170</td>\n",
       "      <td>732</td>\n",
       "      <td>1609</td>\n",
       "      <td>-0.444512</td>\n",
       "      <td>-0.326699</td>\n",
       "      <td>-0.119629</td>\n",
       "      <td>125.507812</td>\n",
       "      <td>66.115723</td>\n",
       "      <td>-20.544434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2099</td>\n",
       "      <td>1990</td>\n",
       "      <td>2400</td>\n",
       "      <td>-0.303887</td>\n",
       "      <td>-0.247598</td>\n",
       "      <td>-0.849121</td>\n",
       "      <td>114.916992</td>\n",
       "      <td>78.112793</td>\n",
       "      <td>-23.005371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>549</td>\n",
       "      <td>795</td>\n",
       "      <td>-0.044609</td>\n",
       "      <td>0.121543</td>\n",
       "      <td>-0.080078</td>\n",
       "      <td>74.860840</td>\n",
       "      <td>85.759277</td>\n",
       "      <td>-71.696777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2493</td>\n",
       "      <td>403</td>\n",
       "      <td>56</td>\n",
       "      <td>0.535469</td>\n",
       "      <td>-1.214395</td>\n",
       "      <td>0.394531</td>\n",
       "      <td>-159.653320</td>\n",
       "      <td>32.036133</td>\n",
       "      <td>45.021973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>967</td>\n",
       "      <td>2464</td>\n",
       "      <td>523</td>\n",
       "      <td>1.506660</td>\n",
       "      <td>0.723594</td>\n",
       "      <td>0.284668</td>\n",
       "      <td>-68.686523</td>\n",
       "      <td>19.445801</td>\n",
       "      <td>137.834473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     p1    p2    p3         x         y         z        roll      pitch  \\\n",
       "0  1170   732  1609 -0.444512 -0.326699 -0.119629  125.507812  66.115723   \n",
       "1  2099  1990  2400 -0.303887 -0.247598 -0.849121  114.916992  78.112793   \n",
       "2    65   549   795 -0.044609  0.121543 -0.080078   74.860840  85.759277   \n",
       "3  2493   403    56  0.535469 -1.214395  0.394531 -159.653320  32.036133   \n",
       "4   967  2464   523  1.506660  0.723594  0.284668  -68.686523  19.445801   \n",
       "\n",
       "          yaw  \n",
       "0  -20.544434  \n",
       "1  -23.005371  \n",
       "2  -71.696777  \n",
       "3   45.021973  \n",
       "4  137.834473  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the data \n",
    "data = pd.read_csv('All_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_train: (10842, 3), C_train: (10842, 3)\n",
      "I_test: (3615, 3), C_test: (3615, 3)\n",
      "I_val: (3615, 3), C_val: (3615, 3)\n"
     ]
    }
   ],
   "source": [
    "# extrap data and create arrays\n",
    "I = data[['x','y','z']].values\n",
    "C = data[['p1','p2','p3']].values\n",
    "# split the matrices into random train and test subjects\n",
    "\n",
    "# splits the data into 80% training and 20% testing for both I and C\n",
    "I_train,I_test,C_train,C_test=train_test_split(I,C,test_size=0.2,random_state=30)\n",
    "# arrays (I,C) , split size (20%) , int in random state allows for same result each time func is called \n",
    "\n",
    "# splits the data again , out of the 80 (training) take another 20 for validation \n",
    "I_train,I_val,C_train,C_val=train_test_split(I_train,C_train,test_size=0.25,random_state=30)\n",
    "# arrays (I and C train) , 25% , rand. int\n",
    "\n",
    "# print the shape of the data to confirm the splits\n",
    "print(f\"I_train: {I_train.shape}, C_train: {C_train.shape}\")\n",
    "print(f\"I_test: {I_test.shape}, C_test: {C_test.shape}\")\n",
    "print(f\"I_val: {I_val.shape}, C_val: {C_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise and conv into compatible data types\n",
    "\n",
    "# Normalise the input features and target values\n",
    "scaler_input = StandardScaler()\n",
    "scaler_output = StandardScaler()\n",
    "\n",
    "\n",
    "# Fit the scalers on the training data and transform all splits\n",
    "I_train = scaler_input.fit_transform(I_train)\n",
    "I_val = scaler_input.transform(I_val)\n",
    "I_test = scaler_input.transform(I_test)\n",
    "\n",
    "C_train = scaler_output.fit_transform(C_train)\n",
    "C_val = scaler_output.transform(C_val)\n",
    "C_test = scaler_output.transform(C_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "I_train = torch.tensor(I_train, dtype=torch.float32)\n",
    "I_val = torch.tensor(I_val, dtype=torch.float32)\n",
    "I_test = torch.tensor(I_test, dtype=torch.float32)\n",
    "\n",
    "C_train = torch.tensor(C_train, dtype=torch.float32)\n",
    "C_val = torch.tensor(C_val, dtype=torch.float32)\n",
    "C_test = torch.tensor(C_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the MLP Regressor model\n",
    "\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84, l3=10, activation='Tanh', dropout_prob=0.2): # set defaults here \n",
    "        super(MLPRegressor, self).__init__()\n",
    "\n",
    "        # Dynamically choose the activation function based on config\n",
    "        self.activation = getattr(nn, activation.capitalize(), nn.Tanh)() \n",
    "\n",
    "        # Define hidden layer params \n",
    "        self.hidden_layers = nn.Sequential(\n",
    "            nn.Linear(3, l1), # input layer -> hidden\n",
    "            self.activation, # acitviation function configured in search space\n",
    "            nn.Dropout(p=dropout_prob), # drop out layer - probability config in search space\n",
    "            nn.Linear(l1, l2), # hidden 1 -> 2\n",
    "            self.activation,\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(l2, l3), # hidden 2 -> 3\n",
    "            self.activation,\n",
    "            nn.Dropout(p=dropout_prob)\n",
    "        )\n",
    "        \n",
    "        # Define output layer with 3 outputs\n",
    "        self.output_layer = nn.Linear(l3, 3)  # hidden 3 -> output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the models\n",
    "model8 = torch.load(\"PR_RT_NR_T26.pickle\",weights_only=False,map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def eval(model, save_path=None):\n",
    "    # Create the testing data loader\n",
    "    test_loader = DataLoader(\n",
    "        TensorDataset(I_test, C_test),\n",
    "        batch_size=64,  # Adjust batch size if necessary\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  # Determine the device to use (GPU if available, else CPU)\n",
    "    # Check for parallel computing ability\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)  # Use multiple GPUs if available\n",
    "    # Assign the model to the chosen device\n",
    "    model.to(device)  # Move the model to the chosen device\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        \"MAPE\": MeanAbsolutePercentageError().to(device),  # Mean Absolute Percentage Error\n",
    "        \"MSE\": MeanSquaredError().to(device),  # Mean Squared Error\n",
    "        \"MAE\": MeanAbsoluteError().to(device)  # Mean Absolute Error\n",
    "    }\n",
    "\n",
    "    # Initialize total metrics\n",
    "    metrics_total = {name: 0.0 for name in metrics}  # Dictionary to store total metrics\n",
    "\n",
    "    # Measure time for a single point\n",
    "    single_point_time = 0.0  # Variable to store the average time per point\n",
    "\n",
    "    # List to store predictions, targets, and inputs\n",
    "    all_predictions = []  # List to store all predictions\n",
    "    all_targets = []  # List to store all targets\n",
    "    all_inputs = []  # List to store all processed inputs\n",
    "    all_inputs_unprocessed = []  # List to store all unprocessed inputs\n",
    "\n",
    "    # Evaluate on test data\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move inputs and targets to the chosen device\n",
    "            start_time = time.time()  # Start time\n",
    "            outputs = model(inputs)  # Get model predictions\n",
    "            end_time = time.time()  # End time\n",
    "            single_point_time += (end_time - start_time) / len(inputs)  # Calculate average time per point\n",
    "            for name, metric in metrics.items():\n",
    "                metrics_total[name] += metric(outputs, targets).item()  # Update total metrics\n",
    "\n",
    "            # Store predictions, targets, and inputs\n",
    "            all_predictions.append(outputs.cpu().numpy())  # Store predictions\n",
    "            all_targets.append(targets.cpu().numpy())  # Store targets\n",
    "            all_inputs.append(inputs.cpu().numpy())  # Store processed inputs\n",
    "            all_inputs_unprocessed.append(scaler_input.inverse_transform(inputs.cpu().numpy()))  # Store unprocessed inputs\n",
    "\n",
    "    # Calculate average metrics\n",
    "    metrics_avg = {name: total / len(test_loader) for name, total in metrics_total.items()}  # Calculate average metrics\n",
    "    metrics_avg['Single Point Time (s)'] = single_point_time / len(test_loader)  # Add time metric\n",
    "\n",
    "    # Save predictions, targets, and inputs to CSV if save_path is provided\n",
    "    if save_path:\n",
    "        predictions = np.concatenate(all_predictions, axis=0)  # Concatenate all predictions\n",
    "        targets = np.concatenate(all_targets, axis=0)  # Concatenate all targets\n",
    "        inputs_processed = np.concatenate(all_inputs, axis=0)  # Concatenate all processed inputs\n",
    "        inputs_unprocessed = np.concatenate(all_inputs_unprocessed, axis=0)  # Concatenate all unprocessed inputs\n",
    "        df = pd.DataFrame(np.hstack((predictions, targets, inputs_processed, inputs_unprocessed)),\n",
    "                         columns=['pred_p1','pred_p2', 'pred_p3',\n",
    "                                  'true_p1', 'true_p2', 'true_p3',\n",
    "                                  'proc_x', 'proc_y', 'proc_z',\n",
    "                                  'unproc_x', 'unproc_y', 'unproc_z'])  # Create DataFrame with all data\n",
    "        df.to_csv(save_path, index=False)  # Save DataFrame to CSV\n",
    "\n",
    "    return metrics_avg  # Return metrics for table display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+----------+-------------------------+\n",
      "| Model   |    MAPE |      MSE |      MAE |   Single Point Time (s) |\n",
      "+=========+=========+==========+==========+=========================+\n",
      "| Model 8 | 1.09312 | 0.163972 | 0.327286 |                 5.8e-05 |\n",
      "+---------+---------+----------+----------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Table Printing for Multiple Models\n",
    "models = {\n",
    "          \"Model 8\": model8\n",
    "          }\n",
    "\n",
    "# Evaluate all models and save outputs\n",
    "results = []  # List to store results\n",
    "for name, model in models.items():  # Loop through all models\n",
    "    metrics_avg = eval(model, save_path=f\"{name}_predictions.csv\")  # Get metrics for the model and save predictions\n",
    "    results.append([name] + [f\"{metrics_avg[metric]:.6f}\" for metric in metrics_avg])  # Append to results list\n",
    "\n",
    "# Header for the table\n",
    "header = [\"Model\"] + list(metrics_avg.keys())\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(results, headers=header, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "MLPRegressor(\n",
      "  (activation): Tanh()\n",
      "  (hidden_layers): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=2048, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Dropout(p=0.2834286389916907, inplace=False)\n",
      "    (3): Linear(in_features=2048, out_features=128, bias=True)\n",
      "    (4): Tanh()\n",
      "    (5): Dropout(p=0.2834286389916907, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=4, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Dropout(p=0.2834286389916907, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n",
      "\n",
      "Optimizer Configuration:\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "Model Summary:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MLPRegressor                             --\n",
      "├─Tanh: 1-1                              --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-1                       8,192\n",
      "│    └─Tanh: 2-2                         --\n",
      "│    └─Dropout: 2-3                      --\n",
      "│    └─Linear: 2-4                       262,272\n",
      "│    └─Tanh: 2-5                         --\n",
      "│    └─Dropout: 2-6                      --\n",
      "│    └─Linear: 2-7                       516\n",
      "│    └─Tanh: 2-8                         --\n",
      "│    └─Dropout: 2-9                      --\n",
      "├─Linear: 1-3                            15\n",
      "=================================================================\n",
      "Total params: 270,995\n",
      "Trainable params: 270,995\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "# Choose a model to print information about\n",
    "model_to_inspect = model8\n",
    "\n",
    "# Print model architecture\n",
    "print(\"Model Architecture:\")\n",
    "print(model_to_inspect)\n",
    "\n",
    "# Print optimizer configuration\n",
    "optimizer = optim.Adam(model_to_inspect.parameters())\n",
    "print(\"\\nOptimizer Configuration:\")\n",
    "print(optimizer)\n",
    "\n",
    "# Print model summary\n",
    "print(\"\\nModel Summary:\")\n",
    "print(summary(model_to_inspect))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "activation': 'Hardtanh', 'alpha': 0.006372252701961378, 'batch_size': 256, 'l1': 256, 'l2': 256, 'l3': 64, 'learning_rate_init': 0.001423761300766936, 'max_iter': 20000, 'tol': 0.0008054526187556726, 'momentum': 0.8856250076974486, 'validation_fraction': 0.17332561677021732, 'dropout_prob': 0.10063715392199685, 'optimiser': 'NAdam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Model 8:\n",
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "MLPRegressor                             --\n",
      "├─Tanh: 1-1                              --\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-1                       8,192\n",
      "│    └─Tanh: 2-2                         --\n",
      "│    └─Dropout: 2-3                      --\n",
      "│    └─Linear: 2-4                       262,272\n",
      "│    └─Tanh: 2-5                         --\n",
      "│    └─Dropout: 2-6                      --\n",
      "│    └─Linear: 2-7                       516\n",
      "│    └─Tanh: 2-8                         --\n",
      "│    └─Dropout: 2-9                      --\n",
      "├─Linear: 1-3                            15\n",
      "=================================================================\n",
      "Total params: 270,995\n",
      "Trainable params: 270,995\n",
      "Non-trainable params: 0\n",
      "=================================================================\n",
      "\n",
      "\u001b[91m================================================================================\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Summary of {name}:\")\n",
    "    print(summary(model))\n",
    "    print(\"\\n\" + \"\\033[91m\" + \"=\"*80 + \"\\033[0m\" + \"\\n\")  # Red color bar\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
